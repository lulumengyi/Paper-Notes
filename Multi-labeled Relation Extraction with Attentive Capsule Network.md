
## 1、题目
 Multi-labeled Relation Extraction with Attentive Capsule Network
### (1)	解释题目 

### (2)	题目是针对什么任务

### (3)	论文的侧重点是模型/算法/数据集？还是？

## 2、摘要

### (1)	发现了什么问题

从一个句子中发现重叠的多重关系仍然是一个挑战,目前大多数的工作都是基于神经模型，假设每个句子都显式地映射到一个关系标签，
不能正确处理多个关系，因为这些关系的重叠特征要么被忽略，要么很难识别。

### (2)	该文大体是怎么解决的

提出了一种利用胶囊网络提取多标记关系的新方法，这种方法在识别单个句子中高度重叠的关系方面比当前的卷积或循环网络有着更好的作用。
为了更好地对特征进行聚类，精确地提取它们之间的关系，我们进一步设计了基于注意的路由算法和滑动边缘损失函数，并将它们嵌入到我们的胶囊网络中。

### (3)	解决得如何

与现有的文献相比，对关系提取有显著的改善。

## 3、介绍

### (1)	任务介绍

### (2)	以往大体如何解决的

现有的神经模型倾向于将低级语义合并为一个高级关系表示向量，并采用max pooling 和word-level 词级注意等方法。然而，一个高层次的关系向量仍然不足以精确地表达多重关系。

### (3)	存在什么问题，你觉得可能还存在什么其他问题？

其次，现有的方法忽略了关系特征的离散化。表示句子关系的一些重要的词都离散的分布在句子中，常用的神经方法处理固定结构的句子，很难收集不同位置的关系特征。

### (4)	该文准备如何解决这个问题？为什么可以这样解决？你觉得该文解决这个问题的方法如何？有没有不完善的地方？你觉得可以如何/或更好的解决这个问题？

该方法的关系提取器由特征提取、特征聚类和关系预测三个主要层次构成。第一种方法提取低级语义。第二层将低级特征聚类为高级关系表示，
最后一层预测每个关系表示的关系类型，利用双向长短期记忆（bi-lstm）和cnn等传统神经模型提取低级特征。
对于功能集群层，我们利用了一个受到Sabour、Frosst和Hinton（2017）启发的专注胶囊网络。

胶囊（向量）是一小部分神经元用来表达特征。它的总长度表明了特征的重要性，而胶囊的方向表明了特征的具体特性。
从第一层开始的低级语义含义被嵌入到大量的低级胶囊中，这些胶囊将被路由并聚集在一起，以表示高级关系特征。

为了更好地提取关系，我们进一步设计了一种基于注意的路由算法，以精确地找到包含相关关系特征的低级胶囊。
此外，我们还提出了一个滑动边际损失函数来解决多标签情况下的“无关联”问题。
只有当所有其他特定类别的概率低于一个界限时，句子才被归类为“无关系”。在训练过程中对边界进行动态调整。

活动向量的长度表示关系特征存在的概率，方向表示一类特征的具体性质

### (5)	列出该文贡献

## 4、模型

### (1)	整体介绍

**Feature Extraction Layer** . Given a sentence b ∗ and two target entities, a Bi-LSTM network is used to extract low-level features of the sentence.

**Feature Clustering Layer**:使用胶囊网络来对低层语义聚合成高层语义信息，

** Relation Predicting Layer** ：利用滑动边际损失函数来预测关系



### (2)	模型创新点

## 5、实验

### (1)	数据集及评价标准介绍

### (2)	Baseline

### (3)	结果分析

## 6、结论

### (1)	你觉得这篇paper创新与贡献是啥？

### (2)	有没有进一步深入的价值

### (3)	列出该文弱点

### (4)	该文对你的启发

